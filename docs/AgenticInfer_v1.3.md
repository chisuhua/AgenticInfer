# **AgenticInferï¼šAgentic-native æ¨ç†å¼•æ“æ¶æ„è®¾è®¡æ–‡æ¡£ v1.3**  
> **å®Œå…¨å…¼å®¹ AgenticDSL v3.7ï¼Œæ— éœ€æ‰©å±•è¯­ä¹‰ï¼Œé€šè¿‡æ ‡å‡† `/lib/reasoning/**` æ¥å£é©±åŠ¨ DAG-native æ¨ç†**

---

## ä¸€ã€è®¾è®¡ç›®æ ‡ä¸æ ¸å¿ƒç†å¿µ

### 1.1 æ ¸å¿ƒç†å¿µï¼ˆä¸¥æ ¼éµå¾ª AgenticDSL v3.7ï¼‰

> **â€œæ¨ç†è¡Œä¸ºåº”æˆä¸ºå¯éªŒè¯ã€å¯ç»„åˆã€å¯å½’æ¡£çš„ DAG èŠ‚ç‚¹ï¼Œè€Œéé»‘ç›’ã€‚â€**

AgenticInfer åœ¨ **ä¸ä¿®æ”¹ AgenticDSL ä»»ä½•è¯­æ³•æˆ–èŠ‚ç‚¹è¯­ä¹‰** çš„å‰æä¸‹ï¼Œå®ç°ï¼š

- âœ… **åŸç”Ÿå…¼å®¹ `llm_call`**ï¼šåˆ©ç”¨è§„èŒƒå…è®¸çš„â€œé¢å¤–å­—æ®µâ€æœºåˆ¶ï¼ˆ5.7ï¼‰  
- âœ… **èƒ½åŠ›å¥‘çº¦åŒ–**ï¼šé€šè¿‡ `/lib/reasoning/**` æ ‡å‡†å­å›¾æš´éœ²æ¨ç†èƒ½åŠ›ï¼ˆ6.2ï¼‰  
- âœ… **èµ„æºå£°æ˜é©±åŠ¨**ï¼šé€šè¿‡ `/__meta__/resources` å£°æ˜ `reasoning` èƒ½åŠ›ï¼ˆ6.4ï¼‰  
- âœ… **å®Œå…¨ä¸‰å±‚æ¶æ„**ï¼šæ‰§è¡ŒåŸè¯­å±‚ (`llm_call`) â†’ æ ‡å‡†åŸè¯­å±‚ (`/lib/reasoning/**`) â†’ çŸ¥è¯†åº”ç”¨å±‚ (`/app/inference/**`)  
- âœ… **å¼•æ“å³åº”ç”¨**ï¼šAgenticInfer æœ¬èº«æ˜¯ä¸€ä¸ª AgenticDSL åº”ç”¨ï¼ˆ`/app/inference/native_engine_v1`ï¼‰

---

## äºŒã€æ•´ä½“æ¶æ„

### 2.1 æ‰§è¡Œæµç¨‹ï¼ˆæ— è¯­ä¹‰æ‰©å±•ï¼‰

```mermaid
flowchart LR
    A[/main/task] --> B[/lib/reasoning/structured_generate@v1]
    B --> C{æ‰§è¡Œå™¨ï¼šæ˜¯å¦å£°æ˜ native_inference_core?}
    C -->|æ˜¯| D[å¯åŠ¨åµŒå¥—å¼•æ“: /app/inference/native_engine_v1]
    C -->|å¦| E[è°ƒç”¨ä¼ ç»Ÿåç«¯ï¼ˆå¦‚ llama.cppï¼‰]
    D --> F[/app/inference/tokenize@v1]
    F --> G[/app/inference/alloc_kv@v1]
    G --> H[/app/inference/run_attention@v1]
    H --> I[/app/inference/apply_grammar@v1]
    I --> J[/app/inference/stream_output@v1]
    J --> K[è¿”å›ä¸»ä¸Šä¸‹æ–‡]
```

### 2.2 è§¦å‘æœºåˆ¶ï¼ˆåˆè§„æ–¹å¼ï¼‰

- ç”¨æˆ·åœ¨ `/__meta__/resources` ä¸­å£°æ˜ï¼š
  ```agentic
  - type: tool
    name: native_inference_core
    scope: internal
  ```
- æ‰§è¡Œå™¨åœ¨ DAG å¯åŠ¨æ—¶æ£€æµ‹è¯¥èµ„æº
- **æ‰€æœ‰ `llm_call` èŠ‚ç‚¹è‡ªåŠ¨è·¯ç”±è‡³ AgenticInfer**
- **æœªå£°æ˜åˆ™é™çº§è‡³ä¼ ç»Ÿåç«¯**

> âœ… **åˆè§„ä¾æ®**ï¼š5.7 å…è®¸ `llm` å¯¹è±¡åŒ…å«é¢å¤–å­—æ®µï¼›6.4 å…è®¸å·¥å…·èµ„æºå£°æ˜

---

## ä¸‰ã€æ ‡å‡†åŸè¯­å±‚ï¼š`/lib/reasoning/**`ï¼ˆå¿…é¡»å®ç°ï¼‰

æ ¹æ® AgenticDSL v3.7 **é™„å½• C** ä¸ **10.2 æ¨ç†åŸè¯­**ï¼Œæ–°å¢ä»¥ä¸‹ 5 ä¸ªæ ‡å‡†å­å›¾ï¼ˆå‡å¸¦ `signature`ï¼‰ï¼š

> å®Œæ•´ YAML å®ç°å·²åœ¨å‰æ–‡æä¾›ï¼Œæ­¤å¤„çœç•¥ï¼Œä»…åˆ—æ¸…å•ï¼š

| å­å›¾ | ç¨³å®šæ€§ | æƒé™ |
|------|--------|------|
| `/lib/reasoning/generate_text@v1` | stable | `reasoning: lmm_generate` |
| `/lib/reasoning/structured_generate@v1` | stable | `reasoning: structured_generate` |
| `/lib/reasoning/continue_from_kv@v1` | stable | `reasoning: lmm_generate` |
| `/lib/reasoning/stream_until@v1` | stable | `reasoning: stream_output` |
| `/lib/reasoning/speculative_decode@v1` | experimental | `reasoning: speculative_decode` |

---

## å››ã€C++ æ‰§è¡ŒåŸè¯­å±‚æ¨¡å—æ¶æ„

AgenticInfer çš„ **C++ æ¨ç†æ ¸å¿ƒ** å®Œå…¨è‡ªç ”ï¼Œæ¨¡å—åŒ–è§£è€¦ï¼Œ**ä¸ä¾èµ– llama.cpp / vLLM / SGLang**ã€‚

### 4.1 é¡¹ç›®ç»“æ„

```text
agentic-native-inference/
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ model/               # Transformer æ¨¡å‹åŠ è½½ä¸æ‰§è¡Œ
â”‚   â”œâ”€â”€ scheduler/           # æ¨ç†ä»»åŠ¡è°ƒåº¦
â”‚   â”œâ”€â”€ kv/                  # åˆ†é¡µ KV ç®¡ç†
â”‚   â”œâ”€â”€ prefix/              # å‰ç¼€å…±äº«ç´¢å¼•
â”‚   â”œâ”€â”€ decode/              # è§£ç ç­–ç•¥
â”‚   â”œâ”€â”€ grammar/             # ç»“æ„åŒ–è¾“å‡ºçº¦æŸ
â”‚   â””â”€â”€ tools/               # æ‰€æœ‰ `tool_call` å®ç°
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”œâ”€â”€ kv/
â”‚   â”œâ”€â”€ prefix/
â”‚   â”œâ”€â”€ decode/
â”‚   â”œâ”€â”€ grammar/
â”‚   â””â”€â”€ tools/
â”œâ”€â”€ kernels/                 # CUDA kernelsï¼ˆpaged_attention.cu, fused_mlp.cuï¼‰
â””â”€â”€ tests/
```

---

### 4.2 æ ¸å¿ƒ C++ æ¨¡å—è®¾è®¡

#### 1. **`ModelLoader`ï¼ˆæ¨¡å‹åŠ è½½å™¨ï¼‰**

```cpp
class ModelLoader {
public:
  static std::unique_ptr<TransformerModel> loadFromGGUF(const std::string& path);
  static std::unique_ptr<TransformerModel> loadFromSafetensors(const std::string& path);
};
```

- æ”¯æŒ GGUF / Safetensors ç›´æ¥è§£æ
- ä¸ä¾èµ– PyTorch / Transformers

#### 2. **`ModelExecutor`ï¼ˆæ¨¡å‹æ‰§è¡Œå™¨ï¼‰**

```cpp
class ModelExecutor {
  std::unique_ptr<TransformerModel> model_;
  std::shared_ptr<KVBlockAllocator> kv_allocator_;

public:
  InferenceStepResult step(
    const std::vector<int>& input_tokens,
    const PageTableRef& kv_cache,
    const LogitsMask* mask = nullptr
  );
};
```

- æ‰‹å†™ CUDA kernelï¼š`paged_attention`, `fused_mlp`
- æ”¯æŒ Q4_K / Q5_K / F16 é‡åŒ–

#### 3. **`KVBlockAllocator`ï¼ˆåˆ†é¡µ KV ç®¡ç†å™¨ï¼‰**

```cpp
class KVBlockAllocator {
  std::vector<GPUPage> physical_pages_;
  std::queue<int> free_pages_;

public:
  PageTableRef allocate(size_t num_blocks);
  void free(const PageTableRef& ref);
  void sharePrefix(const PageTableRef& src, PageTableRef& dst, int shared_len);
};
```

- å…¼å®¹ vLLM PagedAttention æ ¼å¼
- æ”¯æŒ Copy-on-Writeï¼ˆCOWï¼‰

#### 4. **`RadixPrefixIndex`ï¼ˆå‰ç¼€å…±äº«ç´¢å¼•ï¼‰**

```cpp
class RadixPrefixIndex {
  struct RadixNode {
    std::map<int, std::unique_ptr<RadixNode>> children;
    std::optional<PageTableRef> kv_ref;
    int ref_count = 0;
  };

public:
  int registerPrefix(const std::vector<int>& tokens, const PageTableRef& kv);
  std::pair<int, PageTableRef> findLongestPrefix(const std::vector<int>& tokens);
};
```

- å®ç° SGLang çš„ RadixAttention è¯­ä¹‰
- ä¸ DAG `fork` åˆ†æ”¯è‡ªåŠ¨ç»‘å®š

#### 5. **`GrammarCompiler`ï¼ˆç»“æ„åŒ–è¾“å‡ºçº¦æŸï¼‰**

```cpp
class GrammarCompiler {
public:
  static LogitsMask compile(const nlohmann::json& schema);
};
```

- å°† JSON Schema â†’ Context-Free Grammar â†’ Logits Mask
- æ”¯æŒåµŒå¥—å¯¹è±¡ã€æ•°ç»„ã€æšä¸¾

#### 6. **`StreamingController`ï¼ˆæµå¼è¾“å‡ºæ§åˆ¶ï¼‰**

```cpp
class StreamingController {
public:
  std::string streamUntil(
    const std::function<std::pair<float, bool>()>& logits_provider,
    const std::string& stop_condition,
    int max_tokens
  );
};
```

- æ”¯æŒå­—ç¬¦ä¸²/æ­£åˆ™ç»ˆæ­¢æ¡ä»¶
- å†…ç½® `max_tokens` ä¿æŠ¤

---

### 4.3 C++ `tool_call` å®ç°æ˜ å°„

| å·¥å…·å | C++ å®ç° | æ–‡ä»¶ |
|--------|--------|------|
| `native_tokenize` | `Tokenizer::encode()` | `src/tools/tokenize.cpp` |
| `kv_alloc` | `KVBlockAllocator::allocate()` | `src/kv/kv_block_allocator.cpp` |
| `model_step` | `ModelExecutor::step()` | `src/model/model_executor.cpp` |
| `compile_grammar` | `GrammarCompiler::compile()` | `src/grammar/grammar_compiler.cpp` |
| `stream_until` | `StreamingController::streamUntil()` | `src/decode/streaming_controller.cpp` |

> ğŸ”’ æ‰€æœ‰å·¥å…·æ³¨å†Œæ—¶ç»‘å®šæƒé™ï¼š`permissions: [internal: inference_core]`

---

## äº”ã€æ¨ç†å¼•æ“ä¸“å±å·¥ä½œæµï¼š`/app/inference/**`

### 5.1 å¼•æ“å…¥å£ï¼š`/app/inference/native_engine_v1`

```agentic
AgenticDSL '/app/inference/native_engine_v1'
type: assign
assign:
  expr: "{{ $.llm.prompt }}"
  path: "engine_input.prompt"
next: "/app/inference/tokenize@v1"

AgenticDSL '/app/inference/tokenize@v1'
type: tool_call
tool: native_tokenize
arguments:
  text: "{{ $.engine_input.prompt }}"
output_mapping:
  tokens: "engine_state.input_ids"
next: "/app/inference/alloc_kv@v1"

AgenticDSL '/app/inference/alloc_kv@v1'
type: tool_call
tool: kv_alloc
arguments:
  num_blocks: "{{ (len($.engine_state.input_ids) + 255) // 256 }}"
output_mapping:
  block_ids: "engine_state.kv_blocks"
next: "/app/inference/run_attention@v1"

AgenticDSL '/app/inference/run_attention@v1`
type: tool_call
tool: model_step
arguments:
  tokens: "{{ $.engine_state.input_ids }}"
  kv_ref: "{{ $.engine_state.kv_blocks }}"
output_mapping:
  logits: "engine_state.logits"
  updated_kv: "engine_state.kv_blocks"
next: "{{ $.llm.output_schema ? '/app/inference/apply_grammar@v1' : '/app/inference/stream_output@v1' }}"
```

---

## å…­ã€å·¥ä½œæµç¤ºä¾‹

### 6.1 åŸºç¡€ç¤ºä¾‹ï¼šæ–‡æœ¬ç”Ÿæˆ

```agentic
AgenticDSL '/main/greet'
type: assign
assign:
  expr: "Hello"
next: "/lib/reasoning/generate_text@v1"
```

### 6.2 é«˜çº§ç¤ºä¾‹ï¼šç»“æ„åŒ–ç”Ÿæˆ + KV å¤ç”¨

```agentic
AgenticDSL '/main/solve_math'
type: assign
assign:
  expr: "è§£æ–¹ç¨‹: x^2 + 2x + 1 = 0"
next: "/lib/reasoning/structured_generate@v1"

AgenticDSL '/main/explain'
type: assign
assign:
  expr: "è¯·è§£é‡Šä¸ºä»€ä¹ˆæ ¹æ˜¯ -1"
next: "/lib/reasoning/continue_from_kv@v1"
```

---

## ä¸ƒã€AgenticInfer çš„æœ¬è´¨è¶…è¶Šç‚¹

| èƒ½åŠ› | llama.cpp / vLLM / SGLang | AgenticInfer |
|------|-------------------------|-------------|
| **æ§åˆ¶ç²’åº¦** | è¯·æ±‚çº§ / Token çº§ | **DAG èŠ‚ç‚¹çº§**ï¼ˆæ¯æ­¥å¯ `assert` / Traceï¼‰ |
| **ç»„åˆæ€§** | å›ºå®š pipeline | **ä»»æ„ç»„åˆ**ï¼ˆé€šè¿‡ DAG ç¼–æ’ï¼‰ |
| **å¯éªŒè¯æ€§** | é»‘ç›’è¾“å‡º | **è¿‡ç¨‹å¯éªŒè¯**ï¼ˆ`expected_output` + Traceï¼‰ |
| **æ¼”è¿›æ€§** | æ¨¡å‹ä¸ºä¸­å¿ƒ | **å­å›¾ä¸ºä¸­å¿ƒ**ï¼ˆ`archive_to` æˆåŠŸ DAGï¼‰ |
| **ç¼“å­˜å•ä½** | Token å‰ç¼€ | **å­å›¾è¯­ä¹‰ + Token å‰ç¼€** |
| **è°ƒåº¦å•ä½** | è¯·æ±‚ batch | **DAG åˆ†æ”¯æ„ŸçŸ¥ batch** |

> ğŸš€ **æ ¸å¿ƒçªç ´**ï¼šå°†â€œæ¨ç†ç­–ç•¥â€ä» C++ ä»£ç è½¬åŒ–ä¸º DAG èŠ‚ç‚¹ï¼Œå®ç° **æ¨ç†å³ç¨‹åº**ã€‚

---

## å…«ã€åˆè§„æ€§ä¸å®‰å…¨æ€§

| è§„èŒƒè¦æ±‚ | AgenticInfer å®ç° |
|--------|------------------|
| **ä¸‰å±‚æ¶æ„** | âœ… æ— è·¨å±‚è°ƒç”¨ |
| **æ ‡å‡†åº“å¥‘çº¦** | âœ… æ‰€æœ‰ `/lib/reasoning/**` å¸¦ `signature` |
| **æƒé™æœ€å°åŒ–** | âœ… C++ å·¥å…·æƒé™ä¸º `internal` |
| **é¢„ç®—æ§åˆ¶** | âœ… åµŒå¥—å¼•æ“ç»§æ‰¿ `max_nodes * 0.8` |
| **å¯ç»ˆæ­¢æ€§** | âœ… `stream_until` å¼ºåˆ¶ `max_tokens` |
| **Trace** | âœ… æ¯æ­¥è®°å½• `reasoning_evidence` + `backend_used` |

---

## ä¹ã€æ€»ç»“

**AgenticInfer v1.3**ï¼š

- âœ… **å®Œå…¨å…¼å®¹ AgenticDSL v3.7**ï¼Œæ— éœ€ä»»ä½•è¯­ä¹‰æ‰©å±•  
- âœ… **é€šè¿‡æ ‡å‡† `/lib/reasoning/**` å­å›¾æš´éœ²èƒ½åŠ›**  
- âœ… **C++ æ¨¡å—ä»…ä½œä¸º `tool_call` å®ç°**  
- âœ… **æ¨ç†æµç¨‹ç”± `/app/inference/**` DAG ç¼–æ’**  
- âœ… **æœ¬è´¨è¶…è¶Šä¼ ç»Ÿå¼•æ“ï¼šæ¨ç†å³ DAGï¼Œç­–ç•¥å³å­å›¾**

> **æ ‡è¯­**ï¼š  
> **â€œAgenticInfer: Where Inference Becomes a Verifiable DAG.â€**
